{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d7fc40",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40fddf28",
   "metadata": {},
   "source": [
    "Os Embeddings criam uma representação vetorial de um pedaço de texto. Isso é útil porque significa que podemos pensar sobre o texto no espaço vetorial e fazer coisas como busca semântica, onde procuramos por pedaços de texto que são mais semelhantes no espaço vetorial, ou seja, que estão a uma distância menor.\n",
    "\n",
    "A classe Embeddings do Langchain é uma classe projetada para interagir com modelos de embedding de texto. Existem muitos modelos diferentes (OpenAI, Cohere, Hugging Face, etc) - esta classe é projetada para fornecer uma interface padrão para todos eles.\n",
    "\n",
    "A classe de Embeddings base em LangChain fornece dois métodos: um para realizar o emedding de documentos e outro para embedding de uma chamada. O primeiro recebe como entrada vários textos, enquanto o último recebe um único texto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ecb96f8",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/text_embedding/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b05996bd",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/guides/embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75b6dcb5",
   "metadata": {},
   "source": [
    "## Embeddings com OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c871d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-ada-002')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06928c56",
   "metadata": {},
   "source": [
    "### Embedding documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bafa8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedings = embedding_model.embed_documents(\n",
    "    [\n",
    "        'Eu gosto de cochorros',\n",
    "        'Eu gosto de animais',\n",
    "        'O tempo está ruim lá fora'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664d424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a5a244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.014998122015851342,\n",
       " 0.00375574335681561,\n",
       " 0.010847854353812091,\n",
       " -0.018589220813947517,\n",
       " -0.004513726538845811,\n",
       " 0.0025690651788715085,\n",
       " 0.005094639456451029,\n",
       " -0.026019939974831388,\n",
       " 0.00459449502291573,\n",
       " -0.023186823194612204]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a60d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4c4f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74263176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8685d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536 0.23440313178940803 -0.6517162278431541\n",
      "1536 0.23281259520841985 -0.6547135445437406\n",
      "1536 0.2319114644897428 -0.6502302856011555\n"
     ]
    }
   ],
   "source": [
    "for emb in embedings:\n",
    "    print(len(emb), max(emb), min(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c223c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8763941288538092"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embedings[0], embedings[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86f6a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8029946247703756"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embedings[0], embedings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12de8719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7974026032183019"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embedings[1], embedings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "681365b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 | 0.88 | 0.8 | \n",
      "0.88 | 1.0 | 0.8 | \n",
      "0.8 | 0.8 | 1.0 | \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embedings)):\n",
    "    for j in range(len(embedings)):\n",
    "        print(round(np.dot(embedings[i], embedings[j]), 2), end=' | ')\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7302fad",
   "metadata": {},
   "source": [
    "### Embedding query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10f6ef1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.003055812964516579,\n",
       " -0.0013031441232609043,\n",
       " -0.010017073518842389,\n",
       " -0.00260947616363285,\n",
       " -0.010680202187453984,\n",
       " 0.014384797495090555,\n",
       " 0.002634981130335652,\n",
       " -0.005569645561221578,\n",
       " -0.005126497143110168,\n",
       " -0.0021216938791685552]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = 'O que é um cachorro'\n",
    "emb_query = embedding_model.embed_query(pergunta)\n",
    "emb_query[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e82ced4a",
   "metadata": {},
   "source": [
    "## Embedding com HuggingFace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad11d8d7",
   "metadata": {},
   "source": [
    "https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73f5941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avsoares\\OneDrive\\Documentos\\GitHub\\courses\\Langchain\\scripts\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\avsoares\\OneDrive\\Documentos\\GitHub\\courses\\Langchain\\scripts\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\avsoares\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model = 'all-MiniLM-L6-v2'\n",
    "embedding_model = HuggingFaceBgeEmbeddings(model_name = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3726eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedings = embedding_model.embed_documents(\n",
    "    [\n",
    "        'Eu gosto de cochorros',\n",
    "        'Eu gosto de animais',\n",
    "        'O tempo está ruim lá fora'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38518b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 | 0.69 | 0.38 | \n",
      "0.69 | 1.0 | 0.49 | \n",
      "0.38 | 0.49 | 1.0 | \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(len(embedings)):\n",
    "    for j in range(len(embedings)):\n",
    "        print(round(np.dot(embedings[i], embedings[j]), 2), end=' | ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd4c390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 0.13705159723758698 -0.13979804515838623\n",
      "384 0.12528780102729797 -0.1534135490655899\n",
      "384 0.12505857646465302 -0.13441652059555054\n"
     ]
    }
   ],
   "source": [
    "for emb in embedings:\n",
    "    print(len(emb), max(emb), min(emb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
